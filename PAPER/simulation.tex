
\section{Simulation and Results}
\label{sec:simulation}

In this section we will test the proposed \disr{} approach to demonstrate
its effectiveness and compare it against topology agnostic approach
based on spanning trees and
broadcasting~\cite{Patwardhan05evaluatingthe}, to measure how \disr{}
performs in covering the network structure.

%\item Against the centralized segment based approach (SR), to evaluate
%if and how its known properties are still preserved in the new nano-scale distributed scenario

\subsection{Nanoxim Environment}

In order to quantitatively and qualitatively evaluate the proposed approach a
specific simulation environment has been developed, resulting in
the open source and freely available project called
Nanoxim~\cite{nanoxim}.
Nanoxim is a SystemC tool based on a almost rewritten
version of the Noxim Network-on-Chip simulator~\cite{noxim}. While some
complex features have been removed (e.g. wormhole, congestion/topology
aware routing and selection strategies) new features specifically
tailored for the nanoscale scenario were introduced, e.g. the ability to simulate a random
network, the implementation of the \disr{} to obtain the segment topology
and the support for defective links and nodes.

%------------------------------------------------------------------------------
\subsection{Experimental setup}
The following parameters have been taken into account when
performing the \disr{} simulation:
\begin{itemize}
\item {\emph{Size of the network}}: number of nodes, on a range from
10x10 to 100x100 sized networks. 
%\item {\% defective links}: the probability that each link is
%disconnected or not present, from 0 the amount that yields
%no more segments.
\item {\emph{\% defective nodes}}: the probability that a node is not
working, thus having all its links cannot be utilized during \disr{} setup.  
%Same range as defective links parameter.
\item {\emph{Bootstrap node}}: the node used from upper layer 
to inject the \disr{} process. When not explicitly investigating the
impact of each single bootstrap choice, a set representative regions have been
considered, e.g. the central part of the network and the edge corners.
\end{itemize}
To present the results, the following evaluation metrics have been adopted:
\begin{itemize}
\item{Node coverage}: this is the fraction of nodes that
are assigned to a segment. In the ideal case, all the non defective
nodes should be assigned, so this metric is useful to show how some
disconnected regions can negatively impact on the whole \disr{}
effectiveness.
\item{\emph{Latency}}: this measures how the cycles required to complete the
segment assignment scales for increasing network sizes and defect rates
\item{\emph{Bootstrap node effect}}: this evaluates the impact of the chosen
bootstrap node on the node coverage.
\end{itemize}

%Further, to evaluate how \disr{} compares against the centralized segment
%based algorithm, the following metrics have been adopted:
%\begin{itemize}
%%\item {Average Path Length}:
%%\item {Average Link Weight}:
%\item {Unidirectional restrictions:}
%\item {Number of Segments}:
%\end{itemize}

Since the distribution of defects and thus the resulting topology is randomly
generated, a set of simulations with different seeds has been run
for each system configuration. We found that 20 repetitions are
required in order to obtain statistically significant results.


\subsection{Results}
\label{sec:results}

In this section we analyze the results in terms of node
coverage and latency at different network sizes, defect rates and
bootstrap injection points.  In particular
Figure~\ref{fig:results_coverage} shows
node coverage for \disr{} and RPF tree based approach respectively. While
the first aim of \disr{} is not to reach the optimal coverage, we still
can observe a quite good performance as compared to the tree based
approach. Note that defect rates beyond 25\% lead to many disconnected
regions of nodes that \disr{} currently cannot handle.
For example Figure~\ref{fig:net} show a 30x30 network with a 25\%
defect in which the bottom-left part cannot be reached due
disconnected regions. Note that remaining defective nodes belonging to
connected regions are successfully surrounded by \disr{} coverage; in any
case, these defect levels should be considered as worst case scenarios, so the
achieved coverage of $0.5$ is a satisfying result for this first
version of \disr{}. On the other hand, the network size seems to have a
limited impact when defect rate do not introduce too much disconnected
regions. 
\begin{figure*}
\centering
\begin{tabular}{cc}
\includegraphics[width=0.48\textwidth]{pictures/set1.eps} & 
\includegraphics[width=0.48\textwidth]{pictures/coverage.eps} \\
(a) & (b) 
\end{tabular}
\caption{\disr{} (a) and RPF (b) node coverage}
\label{fig:results_coverage}
\end{figure*}

\begin{figure*}
\centering
\includegraphics[width=0.70\textwidth]{pictures/net.ps}
\caption{Covered regions in a 30x30 network with 25\% defects}
\label{fig:net}
\end{figure*}

\begin{figure*}
\centering
\begin{tabular}{cc}
\includegraphics[width=0.48\textwidth]{pictures/set2.eps} & 
\includegraphics[width=0.48\textwidth]{pictures/set2_rpf.eps} \\
(a) & (b)
\end{tabular}
\caption{Latency of \disr{} (a) vs tree based RPF (b) }
\label{fig:results_latency}
\end{figure*}

The number of cycles required to complete segment mapping process
is shown in Figure~\ref{fig:results_latency}. In this case comparison
against tree-based shows better (lower) values at different defect
rates.  Rather than the absolute numbers, what it's more interesting
to observe is how \disr{} latency scales with network size. For example,
going from 900 to 2500 nodes, at the medium defect rate of $0.15$,
leads to an increase from 3000 to 4500 cycles. It should be noticed
also how the effect of defect rate is increasing until the threshold
of $0.25$ is reached, meaning that until that limit \disr{} finds it more
and more difficult to complete the process due increasing defective
paths, but still discover new segments when let running for a more
extended amount of cycles. This behavior is not reported in the RPF
based approach, meaning that a tree based approach, although starting
from higher values, is less affected by defect rates (when low rates
are considered).
After the $0.25$ threshold, the impact of entire disconnected regions
becomes predominant and both approaches become faster in completing
the covering process, since far less nodes can be actually reached. 

Finally, Figure~\ref{fig:results_bootstrap} visually represents  the
stability of the approach against choices of a different bootstrap
node in a 10x10 network.  This is an important aspect to evaluate when
considering that one of the main advantages of \disr{} against all the
tree based approaches should be the ability of choosing whatever
bootstrap node, without having to care about the role assumed in the
future by the chosen root node.  In other words, after segments have
been established, the bootstrap node is like every other node, i.e. it
is not center of a structure, and it is not an hotspot for the traffic
distribution. The results in terms of coverage,  shown for low, medium
and high defect profiles, demonstrate a relatively limited
impact of the bootstrap choice in the low/medium scenarios, while a
$30\%$ instability is found for very high defect rates. This also
sounds acceptable, since when a lot of defective nodes are present, the
particular position of the bootstrap node could lead to a completely
different evolution in the \disr{} setup process.

\begin{figure}
\centering
\includegraphics[width=0.48\textwidth]{pictures/set3.eps}
\caption{Effect of bootstrap node}
\label{fig:results_bootstrap}
\end{figure}

% TODO: long paper
\subsection{Other Optimizations}
Some optimization parameters, which demonstrated to improve the \disr{}
results have been fixed to some good values, but are not subject to
further investigation; once again the focus here is not the
optimal set of segments, but just demonstrating a working approach. 
These are optimizations are:
\begin{itemize}
\item \emph{cycle\_links}: max number of retries across the set of links of
each node. While searching for a free link due an incoming request,
the same request is cancelled after a given number of tries. This
gives to preceding node change to test a different paths. Default is set to 1.
\item \emph{bootstrap\_timeout}: number of time units that a bootstrap node
should wait before assuming that a livelock in the starting segment
process has occurred. In the worst case, we can imagine that longest
path required is the one returning to the bootstrap node after having
traveled across all the links. So, although this is just an extreme
situation, a good upper limit can be safely be set to NxN.
\item \emph{bootstrap\_immunity}: in order to avoid the failure of the whole \disr{}
setup process, a bootstrap node should not have defective links.
Enabling this optimization, a bootstrap node is immune to defects.
We may think of a pre-bootstrap phase that properly selects (from upper
layer via) a bootstrap node which is tested as properly connected. We
enabled this optimization, however empirical tests showed us that only
simulations using bootstrap nodes placed on edges would be heavily
affected, since these are nodes starting with a lower number of links,
e.g. corner nodes could only have two connected direction, so even a
defective link could prevent starting segment packet to return to
bootstrap to close the loop a create the segment.
\end{itemize}
