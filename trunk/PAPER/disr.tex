
%------------------------------------------------------------------------------
\section{Preliminary concepts}
%------------------------------------------------------------------------------
\label{sec:disr_concepts}

\subsection{Basic Idea}
The main concept behind of the original SR approach is the
\emph{Segment}: a Segment is basically a path of consecutive node
and links. 
The idea is to partition the network in a set of disjoint segments, and then
placing a turn restriction within each segment. It has been proved~\cite{}
that such a set of turn prohibitions guarantees dealock freedom and
while preserving connectivity of the network.

Describing the execution phases of DiSR from a top level point-of-view
is basically similar to the classic SR approach. This can be useful to
give an initial idea of the approach, however, some important
differences should be pointed out:(i) no centralized entity is
globally aware of what is going on. The status of the DiSR execution
is collectively distributed among the nodes (ii) no defect map and/or
topology graph is available as input, thus, the topology has to be
discovered \emph{while} segments are created (iii) at the end of the
execution, no segment list is created: Each node is only aware of
belonging to some segment, ignoring the presence of other nodes
in the same segment and even the presence of other segments in the
network.

Roughly speaking, the execution of can be described as the execution
of the following phases:
\begin{itemize}
\item Injection of the DiSR process from upper layer into a bootstrap
node
\item Bootstrap node broadcast to create first segment of the subnet
\item Parallel requests creating other segments
\item Turn proibition in each confirmed segment
\item Draining of remaining packet due timeouts
\end{itemize}

Once again, it should be pointed out that nowhere in the network there
is such a global vision of these exection phases. A more detailed
description of the exection model at each node is discussed in the
next section.

\subsection{Packets types Required}

The DiSR approach works with a distributed mechanism which is build
upon an exchange of small setup packets containing very simple data:
\begin{itemize}
\item{src\_id}: the id of the node that initially originated the
packet
\item{packet\_type}: this encodes that particular meaning of the
packet in the whole DiSR process.
\end{itemize}

As regards packet\_type, we can have the following control packets:
\begin{itemize}
\item{\texttt{STARTING\_SEGMENT\_REQUEST}}: Injected by the bootstrap
node to when searching for the first segment. 
\item{\texttt{STARTING\_SEGMENT\_CONFIRM}}: used when estabilishing
the starting  segment. 
\item{\texttt{SEGMENT\_REQUEST}}: used to search candidates for a segment (not the
first)
\item{\texttt{SEGMENT\_CONFIRM}}: used to estabilish a segment. 
\item{\texttt{SEGMENT\_CANCEL}}: used to cancel the process of searching a segment along a
specific link.
\end{itemize}

\subsection{DiSR Data Structures}

We distinct among two different kind of data stored at each node:
local environment data (LED) and dynamic behaviour status (DBS).

The LED is like a snapshot of the DiSR algorithm at each node,
consisting in the following variables:

\begin{itemize}
\item{segID}:a value used to specify a segment id for the node. Depending on
the values of \emph{visited}/\emph{tvisited} variables below, a node can be
assigned to or candidate for a specific segment id.  
\item{\emph{visited}}: a boolean value. If \emph{visited} is true
and segID is different from NULL, then segID specifies the segment id
to which the node has been assigne. Note that a value different from NULL does not
necessarily mean the node has been assigned to some segment (e.g. when
searching starting segment is set \emph{visited} by default even if not yet
assigned to any segment). 
\item{\emph{tvisited}}: a boolean value. If
true, the node is being considered as candidate for a segment, and the
segID value specifies the segment id for which the node it's candidate. 
\item{\emph{link\_visited[]}}: an array
of values representing information about attached links, that is, the
segID of the segment owning each link. When NULL, the corresponding link has not yet been
assigned.
%TDB: do we need to introduce some value for the
%“bridge” status ? (e.g. a node connecting the terminal node of a
%subnet with the starting one of another) 
\item{\emph{link\_tvisited[]}}: an array of
values representing information about attached links, that is, the segID of
the segment for which the link is candidate. When NULL, the link is
currently not \emph{tvisited}.  
\item{\emph{starting}}: boolean, true if the node it's a
starting node from which the whole process was initiated.
\end{itemize}

In addition to the LED variables described above, further information
should be stored in order to capture the current dynamic behaviour of
the node. This is represented by the dynamic behaviour status (DBS)
variable, which strictly depends on the LED data and the events
occurring at the node. The DBS can have the following values:

\begin{itemize}
\item{\emph{Free}}: a node that has  not been yet considered  by the DiSR algorithm.
The node is not marked as \emph{visited}/\emph{tvisited}/terminal/starting.
\item{\emph{Boostrap}}: a node which has been explicitly set as bootstrap node from
an upper layer via. This is required because a
\texttt{STARTING\_SEGMENT\_REQUEST} packet should be injected in order to start
the whole process.
\item{\emph{ActiveSearching}}: a node from which a find process of new segments has
been started and not yet cancelled or confirmed. This happens when all
the following conditions are matched: the node is marked as \emph{visited},
that is \emph{visited} = TRUE 
TODO: segID is set to some value reflecting
the segment request sent there is a link that is being investigated by
the node, that is a tvisited\_link marked with the same id of the node 
\item{\emph{Candidate}}: a node currently candidate for belonging to some segment
with id segid, not being itself the node from which the find process
was started. The following conditions should be matched: \emph{tvisited} =
true, with segID=X different from node's id.  Two links set as
\emph{link\_tvisited} with id X. Let’s refer them as  links 'i' and 'j'. Then
link\_tvisited[i] was set = X when the find process from an adjacent
node reached the current node, while link\_tvisited[j] has been set to
X when the node itself started to investigate its free links for the
segment request with id X. Note that while investigating its attached
links, if the find process fails along path 'j', the current node can
investigate another free node 'k' if suitable.  
\item{\emph{CandidateStarting}}: same as above, but the node is currently being considered as candidate
for starting segment. Two main differences: Can confirm
\texttt{STARTING\_SEGMENT\_CONFIRM} with the same segID when receiving a normal
\texttt{SEGMENT\_REQUEST}: Overwrites its status setting it to \emph{Candidate} for the
segID frees the links previously set as \emph{tvisited} during flooding
\item{\emph{Assigned}}: a node for which the segment has been determined.  The
segment segID attribute value is set to some id X different from NULL.
The \emph{visited} value is true NOTE: an \emph{Assigned} state is a quick temporary
state, since it becomes \emph{ActiveSearching} if a not (\emph{visited}/tvisited)
link is suitable for searching new segments (see next\_visited
procedure on paper) 
\end{itemize}


\subsection{Creating the starting segment}

\begin{itemize}

\item{Injecting request}: all nodes have status \emph{Free}, except for a
“bootstrap node” with status \emph{Boostrap}, set by some signal from an
upper layer via. This bootstrap node sets itself as \emph{visited} and
changes its status to \emph{ActiveSearching}, injecting a
\texttt{STARTING\_SEGMENT\_REQUEST} across one of its free links. 

\item{Flooding}: Each node receiving a \texttt{STARTING\_SEGMENT\_REQUEST},
if not (\emph{visited}/\emph{tvisited}),  forwards it to its free links using a flooding mechanism.
Each of these links is then marked as \emph{tvisited} with the segment id
associated to the request. Note that a node that has already received a
\texttt{STARTING\_SEGMENT\_REQUEST} packet can simply ignore further packets
associated to the same request, having already contributed to the
flooding. Note also that each of these packets has a max\_segment\_hops
field to prevent packets from travelling undefinitively.  

\item{Confirming the Starting Segment}: when this \texttt{STARTING\_SEGMENT\_REQUEST} packet reaches
the starting node (from a different link, of course), the starting
segment is found. Then the starting node sends back a \texttt{STARTING\_SEGMENT\_CONFIRM}
packet with the same id along the link from which it received the
\texttt{STARTING\_SEGMENT\_REQUEST}. Each node do same by changing its own status
from \emph{tvisited} to \emph{visited}. So the confirmation packet is sent back from
node to node and the starting segment is created. 

Note: A node knows to be \emph{tvisited} due a
\texttt{STARTING\_SEGMENT\_REQUEST}.  Then, when receiving a simple
(not starting) \texttt{SEGMENT\_REQUEST} , can simply cancel its
\emph{tvisited} status and set its links as free, because the second
request means that a starting segment has already been found a
there’s no need to keep the \emph{tvisited} status for those broadcast
status. What happens to nodes not receiving these segment request?
they simply remain \emph{tvisited} and after a timeout reset their
state as free. But they could also remain \emph{tvisited} for the
starting segment, since this doesn’t affect their behaviour for future
segment requests.  

%failure: TODO should we handle this case ? i.e.  marking as terminal ?
\end{itemize}

\subsection{Finding other segments}

\begin{itemize}
\item{Injecting request}: Every node in the \emph{Assigned} status can initiate a search for a
segment, by sending a \texttt{SEGMENT\_REQUEST} across one of its free
links. Note that, since this is not the starting segment, in this case
the packet should not reach the initiator, but just another visited
node

\item{setup of the segment}: The find process is successfull when a visited
node receives the \texttt{SEGMENT\_REQUEST} packet. Then, a \texttt{SEGMENT\_CONFIRM} is
sent back along the path that originated the request.  Failing while
searching a segment: a node received a \texttt{SEGMENT\_REQUEST} packet but
matched one of the following conditions: the node is free but has no
more suitable free links (can’t forward the \texttt{SEGMENT\_REQUEST}) the node
is \emph{tvisited} candidate for another find process the request packet
exceeded the max\_segment\_hops limit.  In all these cases the node
sends back a \texttt{SEGMENT\_CANCEL} along the proper link modifying its state
to free. Each of the subsequent nodes will forward this \texttt{SEGMENT\_CANCEL}
only if no more free links can be explored starting from them.
\end{itemize}


\subsection{Intra-node vs Inter-node parallelism}
In the processes described above, we assumed that each node in the
READY\_SEARCHING state can start a find segment process by injecting a
\texttt{SEGMENT\_REQUEST}. However, a more accurate decision when defining DiSR
should be made in order to decide whether or not the node must
actually perform this action. 
The point above is is strictly related to the general question: which
level of “parallelism” should we allow in DiSR ? The adopted approach
is that, although the nature of DiSR itself is intrinsicly parallel,
the use of parallelism makes things work in a more complex way. In
other words, DiSR is parallel when needed, but it does not exploit
parallelism as an “improving feature”. When not needed, things should
be serialized. For example: when a node is “ready searching” could
start several find segment process associated to the same segment, one
for each free link. But serializing this by investigating the free
links in order could be a simplest solution. We refer to this saying
that we avoid intra-node parallelism.  Note that while intra-node
parallelism can be avoided, trying to avoid inter-node parallelism
could be more complex than allowing the parallelism itself. Imagine
for example the effort of trying to coordinate nodes so that an unique
finding node process is actually running in the whole subnet. Thus, in
contrast to the intra-node parallelism, the inter-node parallelism is
a structural property of the DiSR algorithm and should not be avoided.
%------------------------------------------------------------------------------

\section{Detailed Node behaviour Model}

The LED variables at each node are are initially set so the node and
each of its links is set as free. The only node that makes exception
is the bootstrap node, initialized in the \emph{Bootstrap} status. All
the subsequent events happening at each node are the consequence of
its current dynamic status (DBS) and the packets received, as depicted
in the Figure~\ref{fig:status_machine}.

\label{sec:disr_detailed_model}
%TODO: add state machines

% TODO: fix, move elsewhere or delete
%Assumption: when discussing of visited/\emph{tvisited} nodes, we are assuming
%with an id corresponding to the same subnet. Nodes involved in other
%subnet processes can simply ignore these packets. (TBD: formalize more
%clearly in which cases inter-subnet packets must be ignored, probably
%this happens most of the times, but in some cases, e.g. when a
%terminal node is found, some kind of communication packets are needed
%in order to crearte the bridge between two subnets.) 

\subsection{Receiving a \texttt{STARTING\_SEGMENT\_REQUEST}}

The request for the first segment of a
subnet should be managed differently since all nodes (except the starting
one) must forward the packet using a flooding mechanism. This is
necessary since the request packet must reach the starting node, which
is the only node marked as \emph{visited}. As stated elsewhere, it should
remembered that the first segment of each subnet it's  a loop that
beginning/ending on the starting node.

When a node receives a \texttt{STARTING\_SEGMENT\_REQUEST}, with SegID = X,  there
are the following cases:

\begin{itemize}
\item The node is visited with the same segID = x, that is it was the
initiator of the request (set visited by definition): a first segment
was found and should be confirmed sending back a \texttt{SEGMENT\_CONFIRM}
packet.  
\item The node is \emph{tvisited}, with the same segID of the packet: due
the flooding mechanism, another starting segment packet reached a node
which was previously marked as \emph{tvisited} from the same starting segment
search process. Since the node is \emph{tvisited} with the same id, it means
that it already accomplished in the task of propagating that kind
packets, thus can simply ignore the event thrashing the packet.  If
the node it's not visited/\emph{tvisited}: it should set itself as \emph{tvisited}
and forward the packet along its free links, using flooding. TBD: how
the status should be changed ? depend on the flooding mechanism. Note
that these links don’t include the link from which the request was
received.  
\item The node it's visited, with different id in the packet.
CHECK:  it is not the initiator of the starting segment request, but
is already assigned to some segment!? assuming again we are discussing
of nodes belonging to the same subnet, this should NOT happen, since
the only visited node of the subnet should be the initial node from
which the \texttt{STARTING\_SEGMENT\_REQUEST} originated. Note again that we are
assuming that if the the node is visited or \emph{tvisited} with the id of
another subnet can simply ignore the request.  The node it's \emph{tvisited}
but it's not the initiator of the request (different id): same as
above, if we are assuming nodes of the same subnet, this shouldn’t
happen. If the node is of another subnet, can simply ignore the event.

\end{itemize}

\subsection{Receiving a \texttt{SEGMENT\_REQUEST}}
When a node receives a \texttt{SEGMENT\_REQUEST}, the are the following cases:

\begin{itemize}
\item The node is \emph{visited} (and belongs to the same subnet): a segment was
found and it should be confirmed sending back a \texttt{SEGMENT\_CONFIRM}
packet.  
\item The node is \emph{tvisited}: it should discard the packet sending
back a \texttt{SEGMENT\_CANCEL} 
\item The node it's not \emph{visited}/\emph{tvisited} and has free
links: it marks itself as \emph{tvisited} and forwards the \texttt{SEGMENT\_REQUEST}
(one request at time) to each of its free links, according to some
ordering
\item NOTD: the difference between confirming a \texttt{STARTING\_SEGMENT\_REQUEST}
and confirming a \texttt{SEGMENT\_REQUEST} is that in the first case the node
itself it's included in the segment , while in the second case the
receiving node DOES NOT belong to the segment found. The motivation is
that in the second case the node was already marked as \emph{visited} because
of being assigned to some segment found before, while in the
starting-segment case, by definition, the first segment of a subnet
begins with the starting node, which is marked as \emph{visited} by the SR
algorithm when searching for the first (starting) segment. Remember
that the first segment of a subnet is a loop beginning with the
starting node. 
\end{itemize}

\subsection{Receiving a \texttt{SEGMENT\_CONFIRM}
When received, if the node status is \emph{tvisited} with a segID corresponding to the one indicated in
the packet, the node learns to belong to the segment associated to the
id. Further, it should forward this packet to the link where the
original \texttt{SEGMENT\_REQUEST} packet came from, so that all candidate nodes
can learn the segment id they belong to.  LED shoud be
updated: The state of the node changes from \emph{tvisited} to \emph{visited}.  the
\emph{link\_tvisited} previously set with the segID should be invalidated the
\emph{link\_visited} variable associated to the incoming confirm should be set
as segID. Note that if the request was flooded across different links,
the \emph{link\_visited} variable associated to the other paths shouldn’t be
set.  the \emph{link\_visited} variable associated to the link from which the
request was originated should be set segID

\subsection{Receiving a \texttt{SEGMENT\_CANCEL}}
When a node receives a \texttt{SEGMENT\_CANCEL} packet it means that searching
for a segment along that path was unsuccessful. But if the node still
has other free links to try, it should forward a \texttt{SEGMENT\_REQUEST} to
the next link (next according to some internal ordering). So a node
forwards back the \texttt{SEGMENT\_CANCEL} packet along the link that originated
the \texttt{SEGMENT\_REQUEST} packet ONLY when there are no more free links to
try. If this is the case, the node modifies its status from \emph{tvisited}
to free and fordwards the \texttt{SEGMENT\_CANCEL} packet to the link from which
the request was received. The process stops when the \texttt{SEGMENT\_CANCEL}
packet reach the starting node that originated the request.

TODO REPEAT!!

When a node discovers that the path that includes
the node itself is no more suitable, a \texttt{SEGMENT\_CANCEL} is sent back
across the link from which the \texttt{SEGMENT\_REQUEST} was received.  Possible
reasons for that: The node it’s already candidate for another segment
The node it’s free but can’t find a free link (according the
cyclelinks timeout) The node it’s \emph{tvisited} for the same request id,
previously forwarded that request along some free direction, but now
it’s receiving a a cancel request and has no more free links
